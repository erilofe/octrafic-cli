# v0.2.0

## Changes

- Local LLM support — Ollama and llama.cpp providers (no API key needed)
- Version check — status bar shows when a new version is available
- `/release-notes` command — view latest release notes in TUI
- Think tag filtering for local models (streaming and non-streaming)
- Docs: providers guide page
